{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/manvirkaur84/manvirkaur/blob/main/docs/ml-concepts/207_ML_MSBA/SBACaseLogit%20Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b172f13b",
        "outputId": "c3f142da-78fc-40fb-8a9b-08e618ec3484"
      },
      "source": [
        "%pip install dmba"
      ],
      "id": "b172f13b",
      "execution_count": 278,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: dmba in /usr/local/lib/python3.12/dist-packages (0.2.4)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.12/dist-packages (from dmba) (0.21)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from dmba) (3.10.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from dmba) (2.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from dmba) (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from dmba) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from dmba) (1.16.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->dmba) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->dmba) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->dmba) (4.59.2)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->dmba) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->dmba) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->dmba) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->dmba) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib->dmba) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->dmba) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->dmba) (2025.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->dmba) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->dmba) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib->dmba) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report, roc_auc_score, roc_curve\n",
        "import statsmodels.api as sm\n",
        "import statsmodels.formula.api as smf\n",
        "import matplotlib.pylab as plt\n",
        "import seaborn as sns\n",
        "from dmba import classificationSummary, gainsChart, liftChart\n",
        "from dmba.metric import AIC_score\n",
        "import math\n",
        "from scipy.stats import chi2\n",
        "\n",
        "\n",
        "DATA = Path('/content/sample_data/')"
      ],
      "metadata": {
        "id": "t5-6d3EYsOZH"
      },
      "id": "t5-6d3EYsOZH",
      "execution_count": 279,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#***Section A:*** ⤵\n",
        "####Fit a logistic regression model to reproduce parameter (coefficient) estimates (up to 4 decimals) in Tables 7(a), 8, 9 of this article using the SBA case data SBAcase.11.13.17.csv by using (1) sklearn LogisticRegression() liblinear solver and (2) sklearn LogisticRegression() Default Solver 'lbfgs'.\n",
        "____________"
      ],
      "metadata": {
        "id": "Xve7uL7pm-ed"
      },
      "id": "Xve7uL7pm-ed"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Using sklearn LogisticRegression() liblinear solver"
      ],
      "metadata": {
        "id": "Py7ENgAbre1l"
      },
      "id": "Py7ENgAbre1l"
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Table 7(a).1"
      ],
      "metadata": {
        "id": "89O0mY5HkJ1i"
      },
      "id": "89O0mY5HkJ1i"
    },
    {
      "cell_type": "code",
      "source": [
        "sba_df = pd.read_csv(DATA / 'SBAcase.11.13.17.csv')\n",
        "\n",
        "# TARGET VARIABLE - 'Default' is our dummy variable derived from \"MIS_Status\"\n",
        "# The value for “Default” = 1 if MIS_Status = CHGOFF, and “Default” = 0 if MIS_Status = PIF\n",
        "sba_df['Default'] = np.where(sba_df['MIS_Status'] == 'CHGOFF', 1, 0)\n",
        "sba_df.drop(columns=['MIS_Status'], inplace=True)\n",
        "\n",
        "# Training data only\n",
        "train = sba_df[sba_df['Selected'] == 1].copy()\n",
        "\n",
        "# Predictors for Table 7(a)\n",
        "predictors = ['New', 'RealEstate', 'DisbursementGross', 'Portion', 'Recession']\n",
        "X_train = train[predictors].copy()\n",
        "y_train = train['Default']\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train['DisbursementGross'] = scaler.fit_transform(X_train[['DisbursementGross']])\n",
        "\n",
        "# Fit logistic regression (liblinear, very large C to mimic no penalty)\n",
        "logit_reg = LogisticRegression(solver='liblinear', penalty='l2', C=1e42, max_iter=1000)\n",
        "logit_reg.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "print(\"\\nTable 7(a) Coefficient Estimates\")\n",
        "\n",
        "train_X2 = sm.add_constant(X_train, prepend=True)\n",
        "logit_full2 = sm.GLM(y_train, train_X2, family=sm.families.Binomial())\n",
        "logit_result2 = logit_full2.fit()\n",
        "logit_result2.summary()\n",
        "\n",
        "# Build formatted DataFrame\n",
        "coef_table = pd.DataFrame({\n",
        "    \"Parameter\": train_X2.columns,\n",
        "    \"DF\": [1]*len(logit_result2.params),\n",
        "    \"Estimate\": [f\"{val:.4f}\" if abs(val) >= 1e-4 else f\"{val:.2E}\" for val in logit_result2.params],\n",
        "    \"Standard error\": [f\"{val:.4f}\" if abs(val) >= 1e-4 else f\"{val:.2E}\" for val in logit_result2.bse],\n",
        "    \"Wald Chi-Square\": [f\"{val:.4f}\" for val in (logit_result2.params / logit_result2.bse)**2],\n",
        "    \"Pr > ChiSq\": [\"<0.0001\" if p < 0.0001 else f\"{p:.4f}\" for p in logit_result2.pvalues]\n",
        "})\n",
        "\n",
        "coef_table[\"Parameter\"] = coef_table[\"Parameter\"].replace(\"const\", \"Intercept\")\n",
        "print(coef_table.to_string(index=False))\n"
      ],
      "metadata": {
        "id": "5Zw0gXWysOvj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "397f966d-407b-4379-8a5c-3d5cb4cd77dc"
      },
      "id": "5Zw0gXWysOvj",
      "execution_count": 280,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Table 7(a) Coefficient Estimates\n",
            "        Parameter  DF Estimate Standard error Wald Chi-Square Pr > ChiSq\n",
            "        Intercept   1   1.2704         0.3430         13.7150     0.0002\n",
            "              New   1  -0.0772         0.2101          0.1349     0.7134\n",
            "       RealEstate   1  -2.0331         0.3636         31.2663    <0.0001\n",
            "DisbursementGross   1  -0.1160         0.1211          0.9173     0.3382\n",
            "          Portion   1  -2.8298         0.5594         25.5909    <0.0001\n",
            "        Recession   1   0.4971         0.2413          4.2441     0.0394\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Table 8.1"
      ],
      "metadata": {
        "id": "hl8ZhkRPkaGK"
      },
      "id": "hl8ZhkRPkaGK"
    },
    {
      "cell_type": "code",
      "source": [
        "sba_df = pd.read_csv(DATA / 'SBAcase.11.13.17.csv')\n",
        "\n",
        "# TARGET VARIABLE - 'Default' is our dummy variable derived from \"MIS_Status\"\n",
        "# The value for “Default” = 1 if MIS_Status = CHGOFF, and “Default” = 0 if MIS_Status = PIF\n",
        "sba_df['Default'] = np.where(sba_df['MIS_Status'] == 'CHGOFF', 1, 0)\n",
        "sba_df.drop(columns=['MIS_Status'], inplace=True)\n",
        "\n",
        "# Training data only\n",
        "train = sba_df[sba_df['Selected'] == 1].copy()\n",
        "\n",
        "# Predictors for Table 8\n",
        "predictors = ['RealEstate', 'Portion', 'Recession']\n",
        "X_train = train[predictors]\n",
        "y_train = train['Default']\n",
        "\n",
        "# validation/test set (Selected = 0)\n",
        "valid_X = sba_df[sba_df['Selected'] == 0][predictors]\n",
        "valid_y = sba_df[sba_df['Selected'] == 0]['Default']\n",
        "\n",
        "# Fit logistic regression (liblinear, very large C to mimic no penalty)\n",
        "logit_reg = LogisticRegression(solver='liblinear', penalty='l2', C=1e42, max_iter=1000)\n",
        "logit_reg.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "print(\"\\nTable 7(a) Coefficient Estimates\")\n",
        "\n",
        "train_X2 = sm.add_constant(X_train, prepend=True)\n",
        "logit_full2 = sm.GLM(y_train, train_X2, family=sm.families.Binomial())\n",
        "logit_result2 = logit_full2.fit()\n",
        "\n",
        "# Build formatted DataFrame\n",
        "coef_table = pd.DataFrame({\n",
        "    \"Parameter\": train_X2.columns,\n",
        "    \"DF\": [1]*len(logit_result2.params),\n",
        "    \"Estimate\": [f\"{val:.4f}\" if abs(val) >= 1e-4 else f\"{val:.2E}\" for val in logit_result2.params],\n",
        "    \"Standard error\": [f\"{val:.4f}\" if abs(val) >= 1e-4 else f\"{val:.2E}\" for val in logit_result2.bse],\n",
        "    \"Wald Chi-Square\": [f\"{val:.4f}\" for val in (logit_result2.params / logit_result2.bse)**2],\n",
        "    \"Pr > ChiSq\": [\"<0.0001\" if p < 0.0001 else f\"{p:.4f}\" for p in logit_result2.pvalues]\n",
        "})\n",
        "\n",
        "coef_table[\"Parameter\"] = coef_table[\"Parameter\"].replace(\"const\", \"Intercept\")\n",
        "print(coef_table.to_string(index=False))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aRsBnja8nJbi",
        "outputId": "21f509e0-fde0-4076-d0a9-aec1919bf113"
      },
      "id": "aRsBnja8nJbi",
      "execution_count": 281,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Table 7(a) Coefficient Estimates\n",
            " Parameter  DF Estimate Standard error Wald Chi-Square Pr > ChiSq\n",
            " Intercept   1   1.3931         0.3216         18.7670    <0.0001\n",
            "RealEstate   1  -2.1282         0.3450         38.0529    <0.0001\n",
            "   Portion   1  -2.9875         0.5393         30.6898    <0.0001\n",
            " Recession   1   0.5041         0.2412          4.3679     0.0366\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Table 9.1"
      ],
      "metadata": {
        "id": "BPVMzHqskhZ0"
      },
      "id": "BPVMzHqskhZ0"
    },
    {
      "cell_type": "code",
      "source": [
        "#code from Dicussion Assignment #1  - sklearn LogisticRegression() liblinear solver\n",
        "#Table 9\n",
        "\n",
        "# Validation predictions\n",
        "y_pred = logit_reg.predict(valid_X)\n",
        "\n",
        "# DMBA classification summary\n",
        "#classificationSummary(valid_y, y_pred, class_names=[1, 0])\n",
        "\n",
        "# Confusion matrix\n",
        "cm = confusion_matrix(valid_y, y_pred)\n",
        "tn, fp, fn, tp = cm.ravel()\n",
        "\n",
        "# Build DataFrame with totals\n",
        "conf_table = pd.DataFrame({\n",
        "    \"Classification\": [\n",
        "        \"Higher risk (predicted default)\",\n",
        "        \"Lower risk (predicted non-default)\",\n",
        "        \"Total\"\n",
        "    ],\n",
        "    \"Loans charged off\": [tp, fn, tp+fn],\n",
        "    \"Loans paid in full\": [fp, tn, fp+tn],\n",
        "    \"Total\": [tp+fp, fn+tn, tp+fn+fp+tn]\n",
        "})\n",
        "\n",
        "print(conf_table.to_string(index=False))\n",
        "\n",
        "accuracy = accuracy_score(valid_y, y_pred)\n",
        "misclassification_rate = 1 - accuracy\n",
        "\n",
        "print(f\"Accuracy: {accuracy*100:.2f}%\")\n",
        "print(f\"Misclassification Rate: {misclassification_rate*100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0_UuhCDBSdl5",
        "outputId": "b1c2e65c-c9bb-4e57-ddc1-d0b448db195a"
      },
      "id": "0_UuhCDBSdl5",
      "execution_count": 282,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                    Classification  Loans charged off  Loans paid in full  Total\n",
            "   Higher risk (predicted default)                 31                  14     45\n",
            "Lower risk (predicted non-default)                324                 682   1006\n",
            "                             Total                355                 696   1051\n",
            "Accuracy: 67.84%\n",
            "Misclassification Rate: 32.16%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using sklearn LogisticRegression() Default Solver **'lbfgs'**"
      ],
      "metadata": {
        "id": "-S-DewFKY_C4"
      },
      "id": "-S-DewFKY_C4"
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Table 7(a).2\n"
      ],
      "metadata": {
        "id": "6oVjdjy9kx4q"
      },
      "id": "6oVjdjy9kx4q"
    },
    {
      "cell_type": "code",
      "source": [
        "sba_df = pd.read_csv(DATA / 'SBAcase.11.13.17.csv')\n",
        "\n",
        "# TARGET VARIABLE - 'Default' is our dummy variable derived from \"MIS_Status\"\n",
        "# The value for “Default” = 1 if MIS_Status = CHGOFF, and “Default” = 0 if MIS_Status = PIF\n",
        "sba_df['Default'] = np.where(sba_df['MIS_Status'] == 'CHGOFF', 1, 0)\n",
        "sba_df.drop(columns=['MIS_Status'], inplace=True)\n",
        "\n",
        "# Training data only\n",
        "train = sba_df[sba_df['Selected'] == 1].copy()\n",
        "\n",
        "# Predictors for Table 7(a)\n",
        "predictors = ['New', 'RealEstate', 'DisbursementGross', 'Portion', 'Recession']\n",
        "X_train = train[predictors].copy()\n",
        "y_train = train['Default']\n",
        "\n",
        "# validation/test set (Selected = 0)\n",
        "valid_X = sba_df[sba_df['Selected'] == 0][predictors]\n",
        "valid_y = sba_df[sba_df['Selected'] == 0]['Default']\n",
        "\n",
        "logit_reg_default = LogisticRegression(penalty=None, solver='lbfgs', max_iter=10000)\n",
        "logit_reg_default.fit(X_train, y_train)\n",
        "\n",
        "print(\"\\nTable 7(a) Coefficient Estimates\")\n",
        "\n",
        "train_X2 = sm.add_constant(X_train, prepend=True)\n",
        "logit_full2 = sm.GLM(y_train, train_X2, family=sm.families.Binomial())\n",
        "logit_result2 = logit_full2.fit()\n",
        "\n",
        "# Build formatted DataFrame\n",
        "coef_table = pd.DataFrame({\n",
        "    \"Parameter\": train_X2.columns,\n",
        "    \"DF\": [1]*len(logit_result2.params),\n",
        "    \"Estimate\": [f\"{val:.4f}\" if abs(val) >= 1e-4 else f\"{val:.2E}\" for val in logit_result2.params],\n",
        "    \"Standard error\": [f\"{val:.4f}\" if abs(val) >= 1e-4 else f\"{val:.2E}\" for val in logit_result2.bse],\n",
        "    \"Wald Chi-Square\": [f\"{val:.4f}\" for val in (params / logit_result2.bse)**2],\n",
        "    \"Pr > ChiSq\": [\"<0.0001\" if p < 0.0001 else f\"{p:.4f}\" for p in logit_result2.pvalues]\n",
        "})\n",
        "\n",
        "coef_table[\"Parameter\"] = coef_table[\"Parameter\"].replace(\"const\", \"Intercept\")\n",
        "print(coef_table.to_string(index=False))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CcxzjuzrZGEG",
        "outputId": "aff40209-a238-4291-c0fd-4634f55787f4"
      },
      "id": "CcxzjuzrZGEG",
      "execution_count": 283,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Table 7(a) Coefficient Estimates\n",
            "        Parameter  DF  Estimate Standard error Wald Chi-Square Pr > ChiSq\n",
            "        Intercept   1    1.3537         0.3229         17.5729    <0.0001\n",
            "              New   1   -0.0772         0.2101          0.1349     0.7134\n",
            "       RealEstate   1   -2.0331         0.3636         31.2663    <0.0001\n",
            "DisbursementGross   1 -3.37E-07       3.52E-07          0.9173     0.3382\n",
            "          Portion   1   -2.8298         0.5594         25.5909    <0.0001\n",
            "        Recession   1    0.4971         0.2413          4.2441     0.0394\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Table 8.2"
      ],
      "metadata": {
        "id": "vVbZ7BEFk2oy"
      },
      "id": "vVbZ7BEFk2oy"
    },
    {
      "cell_type": "code",
      "source": [
        "sba_df = pd.read_csv(DATA / 'SBAcase.11.13.17.csv')\n",
        "\n",
        "# TARGET VARIABLE - 'Default' is our dummy variable derived from \"MIS_Status\"\n",
        "# The value for “Default” = 1 if MIS_Status = CHGOFF, and “Default” = 0 if MIS_Status = PIF\n",
        "sba_df['Default'] = np.where(sba_df['MIS_Status'] == 'CHGOFF', 1, 0)\n",
        "sba_df.drop(columns=['MIS_Status'], inplace=True)\n",
        "\n",
        "# Training data only\n",
        "train = sba_df[sba_df['Selected'] == 1].copy()\n",
        "\n",
        "# Predictors for Table 7(a)\n",
        "predictors = ['RealEstate', 'Portion', 'Recession']\n",
        "X_train = train[predictors].copy()\n",
        "y_train = train['Default']\n",
        "\n",
        "# validation/test set (Selected = 0)\n",
        "valid_X = sba_df[sba_df['Selected'] == 0][predictors]\n",
        "valid_y = sba_df[sba_df['Selected'] == 0]['Default']\n",
        "\n",
        "logit_reg_default = LogisticRegression(penalty=None, solver='lbfgs', max_iter=10000)\n",
        "logit_reg_default.fit(X_train, y_train)\n",
        "\n",
        "print(\"\\nTable 7(a) Coefficient Estimates\")\n",
        "\n",
        "train_X2 = sm.add_constant(X_train, prepend=True)\n",
        "logit_full2 = sm.GLM(y_train, train_X2, family=sm.families.Binomial())\n",
        "logit_result2 = logit_full2.fit()\n",
        "\n",
        "# Build formatted DataFrame\n",
        "coef_table = pd.DataFrame({\n",
        "    \"Parameter\": train_X2.columns,\n",
        "    \"DF\": [1]*len(logit_result2.params),\n",
        "    \"Estimate\": [f\"{val:.4f}\" if abs(val) >= 1e-4 else f\"{val:.2E}\" for val in logit_result2.params],\n",
        "    \"Standard error\": [f\"{val:.4f}\" if abs(val) >= 1e-4 else f\"{val:.2E}\" for val in logit_result2.bse],\n",
        "    \"Wald Chi-Square\": [f\"{val:.4f}\" for val in (logit_result2.params / logit_result2.bse)**2],\n",
        "    \"Pr > ChiSq\": [\"<0.0001\" if p < 0.0001 else f\"{p:.4f}\" for p in logit_result2.pvalues]\n",
        "})\n",
        "\n",
        "coef_table[\"Parameter\"] = coef_table[\"Parameter\"].replace(\"const\", \"Intercept\")\n",
        "print(coef_table.to_string(index=False))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1N1BlHFhenEg",
        "outputId": "b3b56a0e-5b88-4680-c583-b2dd9941a869"
      },
      "id": "1N1BlHFhenEg",
      "execution_count": 284,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Table 7(a) Coefficient Estimates\n",
            " Parameter  DF Estimate Standard error Wald Chi-Square Pr > ChiSq\n",
            " Intercept   1   1.3931         0.3216         18.7670    <0.0001\n",
            "RealEstate   1  -2.1282         0.3450         38.0529    <0.0001\n",
            "   Portion   1  -2.9875         0.5393         30.6898    <0.0001\n",
            " Recession   1   0.5041         0.2412          4.3679     0.0366\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Table 9.2"
      ],
      "metadata": {
        "id": "Yo3YuEgok-WD"
      },
      "id": "Yo3YuEgok-WD"
    },
    {
      "cell_type": "code",
      "source": [
        "# Validation predictions\n",
        "y_pred = logit_reg.predict(valid_X)\n",
        "\n",
        "# Then: get confusion matrix values\n",
        "cm = confusion_matrix(valid_y, y_pred)\n",
        "tn, fp, fn, tp = cm.ravel() #unpacks values directly from the confusion matrix\n",
        "\n",
        "# Build textbook-style table with totals\n",
        "table = pd.DataFrame({\n",
        "    \"Classification\": [\n",
        "        \"Higher risk (predicted default)\",\n",
        "        \"Lower risk (predicted paid in full)\",\n",
        "        \"Total\"\n",
        "    ],\n",
        "    \"Loans charged off\": [tp, fn, tp+fn],\n",
        "    \"Loans paid in full\": [fp, tn, fp+tn],\n",
        "    \"Total\": [tp+fp, fn+tn, tp+fn+fp+tn]\n",
        "})\n",
        "\n",
        "print(\"\\nTable 9 California-based scenario: Classification of Loans.\")\n",
        "print(table.to_string(index=False))\n",
        "\n",
        "accuracy = accuracy_score(valid_y, y_pred)\n",
        "misclassification_rate = 1 - accuracy\n",
        "\n",
        "print(f\"Accuracy: {accuracy*100:.2f}%\")\n",
        "print(f\"Misclassification Rate: {misclassification_rate*100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ib-1rTJme12G",
        "outputId": "b1781cc2-cf7b-4ac2-87e9-62867867eb0a"
      },
      "id": "ib-1rTJme12G",
      "execution_count": 285,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Table 9 California-based scenario: Classification of Loans.\n",
            "                     Classification  Loans charged off  Loans paid in full  Total\n",
            "    Higher risk (predicted default)                 31                  14     45\n",
            "Lower risk (predicted paid in full)                324                 682   1006\n",
            "                              Total                355                 696   1051\n",
            "Accuracy: 67.84%\n",
            "Misclassification Rate: 32.16%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#***Section B*** ⤵\n",
        "####Refer to Table 8 of the article. Write the estimated equation that associates the outcome variable (i.e., default or not) with predictors RealEstate, Portion, and Recession, in three formats:\n",
        "* The logit as a function of the predictors\n",
        "* The odds as a function of the predictors\n",
        "* The probability as a function of the predictors\n",
        "------\n"
      ],
      "metadata": {
        "id": "D2rXV_IBnjS0"
      },
      "id": "D2rXV_IBnjS0"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Estimated Equation(s):\n",
        "* B0 = Intercept\n",
        "* B2 = RealEstate\n",
        "* B3 = Portion\n",
        "* B4 = Recession\n",
        "\n",
        "p = P(Default = 1 | RealEstate, Portion, Recession)\n",
        "\n",
        "1) Logit Function = ln(1/(1-p)) = B0 + B1X1 + B2X2 + B3X3\n",
        "* ln(1/(1-p)) = 1.3931 + (-2.1821 * X1) + (-2.9875 * X2) + (0.5041 * X3)\n",
        "\n",
        "2) Odds Function = p/(1-p) = e^logit\n",
        "* e^[1.3931 + (-2.1821 * X1) + (-2.9875 * X2) + (0.5041 * X3)]\n",
        "\n",
        "3) Probability Function = p = (odds/1+odds)\n",
        "* [(e^[1.3931 + (-2.1821 * X1) + (-2.9875 * X2) + (0.5041 * X3))/(1+e^[1.3931 + (-2.1821 * X1) + (-2.9875 * X2) + (0.5041 * X3))]"
      ],
      "metadata": {
        "id": "suiBVpXyn95x"
      },
      "id": "suiBVpXyn95x"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#***Section C*** ⤵\n",
        "#####Explain why risk indicators in Table 8 were selected using p-values in Table 7(a).\n",
        "------\n"
      ],
      "metadata": {
        "id": "ML6N2tWWokxt"
      },
      "id": "ML6N2tWWokxt"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Risk indicators in Table 8 were selected using p-values from Table 7(a) to make the model simpler and reliable. Table 7(a) had 5 variables, but DisembursementGross and New were dropped beacaue their p-values were greater than 0.05, which made them statistically insignificant causing them to have no serious effect on the data. The remaining variables all had p-values less than 0.05 and were selected."
      ],
      "metadata": {
        "id": "bXJTFUPvxOpI"
      },
      "id": "bXJTFUPvxOpI"
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}